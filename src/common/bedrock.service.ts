import {
  BedrockRuntimeClient,
  InvokeModelCommand,
  InvokeModelWithResponseStreamCommand,
  ResponseStream,
} from '@aws-sdk/client-bedrock-runtime';
import { Injectable, Logger } from '@nestjs/common';

import { INSIGHT_GENERATION_PROMPT } from '../prompts/insight-generation.prompt';
import { QUERY_ANALYSIS_PROMPT } from '../prompts/query-analysis.prompt';
import { VISUALIZATION_SELECTION_PROMPT } from '../prompts/visualization-selection.prompt';

export interface ClaudeMessage {
  role: 'user' | 'assistant';
  content: string;
}

export interface ClaudeRequest {
  anthropic_version: string;
  messages: ClaudeMessage[];
  max_tokens?: number;
  temperature?: number;
  system?: string;
}

export interface ClaudeResponse {
  content: Array<{
    type: string;
    text: string;
  }>;
  stop_reason: string;
  usage: {
    input_tokens: number;
    output_tokens: number;
  };
}

@Injectable()
export class BedrockService {
  private readonly logger = new Logger(BedrockService.name);
  private client: BedrockRuntimeClient;
  private readonly modelId: string;

  constructor() {
    this.client = new BedrockRuntimeClient({
      region: process.env.AWS_REGION || 'us-east-1',
    });
    this.modelId = process.env.BEDROCK_MODEL_ID || 'anthropic.claude-3-sonnet-20240229-v1:0';
  }

  /**
   * Claude 3 ëª¨ë¸ í˜¸ì¶œ
   * @param messages ëŒ€í™” ë©”ì‹œì§€ ë°°ì—´
   * @param options ì¶”ê°€ ì˜µì…˜ (max_tokens, temperature, system)
   * @returns Claude ì‘ë‹µ
   */
  async invokeModel(
    messages: ClaudeMessage[],
    options?: {
      max_tokens?: number;
      temperature?: number;
      system?: string;
    },
  ): Promise<ClaudeResponse> {
    const request: ClaudeRequest = {
      anthropic_version: 'bedrock-2023-05-31',
      messages,
      max_tokens: options?.max_tokens || 4096,
      temperature: options?.temperature || 0.7,
      ...(options?.system && { system: options.system }),
    };

    this.logger.log(`Invoking Bedrock model: ${this.modelId}`);
    this.logger.debug(`Request: ${JSON.stringify(request, null, 2)}`);

    try {
      const command = new InvokeModelCommand({
        modelId: this.modelId,
        contentType: 'application/json',
        accept: 'application/json',
        body: JSON.stringify(request),
      });

      const response = await this.client.send(command);
      const responseBody = JSON.parse(new TextDecoder().decode(response.body)) as ClaudeResponse;

      this.logger.log(
        `Model invoked successfully. Tokens used: ${responseBody.usage.input_tokens} in, ${responseBody.usage.output_tokens} out`,
      );
      this.logger.debug(`Response: ${JSON.stringify(responseBody, null, 2)}`);

      return responseBody;
    } catch (error) {
      this.logger.error('Failed to invoke Bedrock model', error);
      throw error;
    }
  }

  /**
   * Claude 3 ëª¨ë¸ í˜¸ì¶œ (ìŠ¤íŠ¸ë¦¬ë°)
   * @param messages ëŒ€í™” ë©”ì‹œì§€ ë°°ì—´
   * @param options ì¶”ê°€ ì˜µì…˜
   * @returns ìŠ¤íŠ¸ë¦¼ ì‘ë‹µ
   */
  async invokeModelWithStream(
    messages: ClaudeMessage[],
    options?: {
      max_tokens?: number;
      temperature?: number;
      system?: string;
    },
  ): Promise<AsyncIterable<ResponseStream>> {
    const request: ClaudeRequest = {
      anthropic_version: 'bedrock-2023-05-31',
      messages,
      max_tokens: options?.max_tokens || 4096,
      temperature: options?.temperature || 0.7,
      ...(options?.system && { system: options.system }),
    };

    this.logger.log(`Invoking Bedrock model with streaming: ${this.modelId}`);

    try {
      const command = new InvokeModelWithResponseStreamCommand({
        modelId: this.modelId,
        contentType: 'application/json',
        accept: 'application/json',
        body: JSON.stringify(request),
      });

      const response = await this.client.send(command);

      if (!response.body) {
        throw new Error('No response body received from Bedrock');
      }

      return response.body;
    } catch (error) {
      this.logger.error('Failed to invoke Bedrock model with streaming', error);
      throw error;
    }
  }

  /**
   * Text-to-SQL ë³€í™˜ì„ ìœ„í•œ í—¬í¼ ë©”ì„œë“œ
   * @param userQuery ì‚¬ìš©ì ìì—°ì–´ ì§ˆì˜
   * @param schema ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´
   * @returns SQL ì¿¼ë¦¬
   */
  async generateSQL(userQuery: string, schema: string): Promise<string> {
    const systemPrompt = `You are an expert SQL query generator.
Given a database schema and a natural language query, generate a valid MySQL query.
Only return the SQL query without any explanation or markdown formatting.`;

    const userMessage = `Database Schema:
${schema}

User Query: ${userQuery}

Generate a MySQL query for the above request.`;

    const response = await this.invokeModel(
      [
        {
          role: 'user',
          content: userMessage,
        },
      ],
      {
        system: systemPrompt,
        max_tokens: 2048,
        temperature: 0.3, // ë‚®ì€ temperatureë¡œ ì¼ê´€ì„± ìˆëŠ” SQL ìƒì„±
      },
    );

    if (response.content && response.content.length > 0) {
      return response.content[0].text.trim();
    }

    throw new Error('No SQL query generated from Bedrock response');
  }

  /**
   * ì§ˆì˜ ë¶„ì„ (Phase 7)
   * ì‚¬ìš©ì ì§ˆì˜ê°€ ë¶ˆì¶©ë¶„í•œì§€ íŒë‹¨í•˜ê³  í•„ìš”ì‹œ ì¶”ê°€ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤
   * @param userQuery ì‚¬ìš©ì ì§ˆë¬¸
   * @returns ì§ˆì˜ ë¶„ì„ ê²°ê³¼ (ì¶”ê°€ ì§ˆë¬¸ í¬í•¨ ì—¬ë¶€)
   */
  async analyzeQuery(userQuery: string): Promise<{
    needsClarification: boolean;
    reason?: string;
    questions?: Array<{
      type: 'period' | 'limit' | 'filter' | 'grouping' | 'category';
      question: string;
      options: string[];
      default: string;
    }>;
  }> {
    const prompt = QUERY_ANALYSIS_PROMPT.replace('{{USER_QUERY}}', userQuery);

    this.logger.log('Analyzing user query for clarification needs');

    const response = await this.invokeModel(
      [
        {
          role: 'user',
          content: prompt,
        },
      ],
      {
        max_tokens: 2048,
        temperature: 0.5,
      },
    );

    if (response.content && response.content.length > 0) {
      const textContent = response.content[0].text.trim();

      // JSON ì‘ë‹µ íŒŒì‹± (ì½”ë“œ ë¸”ë¡ì´ë‚˜ ë§ˆí¬ë‹¤ìš´ ì œê±°)
      const jsonMatch = textContent.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        try {
          const result = JSON.parse(jsonMatch[0]);
          this.logger.log(`Query analysis complete. Needs clarification: ${result.needsClarification}`);
          return result;
        } catch (error) {
          this.logger.error('Failed to parse query analysis JSON', error);
          // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
          return {
            needsClarification: false,
          };
        }
      }
    }

    throw new Error('No query analysis result from Bedrock response');
  }

  /**
   * ì¸ì‚¬ì´íŠ¸ ìƒì„± (Phase 7)
   * SQL ì¿¼ë¦¬ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ í’ë¶€í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤
   * @param userQuery ì‚¬ìš©ì ì§ˆë¬¸
   * @param sqlQuery ì‹¤í–‰ëœ SQL
   * @param queryResults ì¿¼ë¦¬ ê²°ê³¼ ë°ì´í„°
   * @returns AI ë¶„ì„ ì¸ì‚¬ì´íŠ¸
   */
  async generateInsights(
    userQuery: string,
    sqlQuery: string,
    queryResults: unknown[],
  ): Promise<{
    summary: string;
    keyFindings: string[];
    comparison?: string;
    trend?: string;
    anomaly?: string;
    recommendation?: string;
  }> {
    const prompt = INSIGHT_GENERATION_PROMPT.replace('{{USER_QUERY}}', userQuery)
      .replace('{{SQL_QUERY}}', sqlQuery)
      .replace('{{QUERY_RESULTS}}', JSON.stringify(queryResults, null, 2));

    this.logger.log('Generating insights from query results');

    const response = await this.invokeModel(
      [
        {
          role: 'user',
          content: prompt,
        },
      ],
      {
        max_tokens: 3072,
        temperature: 0.7,
      },
    );

    if (response.content && response.content.length > 0) {
      const textContent = response.content[0].text.trim();

      // JSON ì‘ë‹µ íŒŒì‹±
      const jsonMatch = textContent.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        try {
          const result = JSON.parse(jsonMatch[0]);
          this.logger.log('Insights generated successfully');
          return result;
        } catch (error) {
          this.logger.error('Failed to parse insights JSON', error);
          // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸ ë°˜í™˜
          return {
            summary: 'ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.',
            keyFindings: ['ğŸ“Š ì¿¼ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤'],
          };
        }
      }
    }

    throw new Error('No insights generated from Bedrock response');
  }

  /**
   * ì‹œê°í™” ì„ íƒ (Phase 7)
   * ë°ì´í„° íŠ¹ì„±ì— ë”°ë¼ ìµœì ì˜ ì‹œê°í™” ë°©ë²•ì„ ê²°ì •í•©ë‹ˆë‹¤
   * @param userQuery ì‚¬ìš©ì ì§ˆë¬¸
   * @param sqlQuery ì‹¤í–‰ëœ SQL
   * @param queryResults ì¿¼ë¦¬ ê²°ê³¼ ë°ì´í„°
   * @returns ì‹œê°í™” ì¶”ì²œ ì •ë³´
   */
  async selectVisualization(
    userQuery: string,
    sqlQuery: string,
    queryResults: unknown[],
  ): Promise<{
    type: 'chart' | 'table' | 'both';
    chartType?: 'bar' | 'line' | 'pie';
    reason: string;
  }> {
    // ê²°ê³¼ êµ¬ì¡° ë¶„ì„ (ì»¬ëŸ¼ëª…, ë°ì´í„° íƒ€ì… ë“±)
    const resultStructure =
      queryResults.length > 0
        ? {
            columns: Object.keys(queryResults[0] as Record<string, unknown>),
            rowCount: queryResults.length,
            sample: queryResults[0],
          }
        : { columns: [], rowCount: 0, sample: null };

    const prompt = VISUALIZATION_SELECTION_PROMPT.replace('{{USER_QUERY}}', userQuery)
      .replace('{{SQL_QUERY}}', sqlQuery)
      .replace('{{RESULT_STRUCTURE}}', JSON.stringify(resultStructure, null, 2));

    this.logger.log('Selecting optimal visualization type');

    const response = await this.invokeModel(
      [
        {
          role: 'user',
          content: prompt,
        },
      ],
      {
        max_tokens: 1536,
        temperature: 0.5,
      },
    );

    if (response.content && response.content.length > 0) {
      const textContent = response.content[0].text.trim();

      // JSON ì‘ë‹µ íŒŒì‹±
      const jsonMatch = textContent.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        try {
          const result = JSON.parse(jsonMatch[0]);
          this.logger.log(`Visualization selected: ${result.type}${result.chartType ? ` (${result.chartType})` : ''}`);
          return result;
        } catch (error) {
          this.logger.error('Failed to parse visualization JSON', error);
          // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‹œê°í™” ë°˜í™˜
          return {
            type: 'table',
            reason: 'ë°ì´í„°ë¥¼ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.',
          };
        }
      }
    }

    throw new Error('No visualization selection from Bedrock response');
  }
}
